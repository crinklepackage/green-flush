# Request Flow Documentation

## Overview
This document describes the complete flow of a podcast summary request, updated to incorporate a modular approach to streaming summary results.

## High-Level Flow Diagram
[Note: The following represents a sequence diagram. Consider visualizing with Mermaid or a similar tool]

Client -> API: Submit URL (POST /api/podcasts)
API -> External Services: Fetch metadata
API -> Supabase: Create podcast record
API -> Supabase: Create summary record (status: IN_QUEUE)
API -> Redis Queue: Enqueue processing job
API -> Client: Return summaryId

Worker -> Redis Queue: Dequeue job
Worker -> Supabase: Update status (FETCHING_TRANSCRIPT)
Worker -> External Services: Fetch transcript
Worker -> Supabase: Update status (GENERATING_SUMMARY)
Worker -> External Services: Generate summary in chunks
Worker -> Supabase: Append summary chunks incrementally & Update status (COMPLETED)

[Note: Real-time updates happen via Supabase subscriptions throughout the process]

## Detailed Component Responsibilities

1. API Service (ApiService)
   Constructor dependencies:
   - youtube: YouTubeApiClient
   - spotify: SpotifyApiClient
   - supabase: SupabaseClient
   - podcastQueue: Queue

   Responsibilities:
   - Validates incoming URLs
   - Fetches initial metadata via platform clients
   - Creates database records
   - Enqueues processing jobs

2. Worker Service (WorkerService)
   Constructor dependencies:
   - youtube: YouTubeApiClient
   - transcriptProcessor: TranscriptProcessor
   - summaryProcessor: SummaryProcessor
   - supabase: SupabaseClient

   Responsibilities:
   - Processes queued jobs
   - Handles transcript acquisition
   - Manages summary generation
   - Updates record statuses

3. Content Processor Service (ContentProcessorService) [New]
   - **Phase 1: DB-Backed Streaming**
     - Processes the job by fetching the transcript and generating the summary in chunks using a streaming API (e.g., Anthropic via Claude).
     - As each summary chunk is generated, it is immediately appended to the summary record in the database.
     - The summary status is updated step-by-step: IN_QUEUE → FETCHING_TRANSCRIPT → GENERATING_SUMMARY → COMPLETED (or FAILED on error).
     - The UI subscribes to the summary record via Supabase realtime subscriptions so that chunks appear incrementally with minimal latency (roughly 300–500 ms per chunk).
   
   - **Phase 2: Direct Streaming via SSE (Future Enhancement)**
     - Instead of (or in parallel with) writing chunks to the database, a dedicated SSE (or WebSocket) endpoint would be used to push chunks directly to the client.
     - A delivery abstraction (e.g., a StreamDeliveryService interface) would allow swapping the DB-backed model with direct streaming with minimal changes to the core processing logic.
     - This approach would minimize latency but requires robust connection management and client-side logic for reconnection.

## Transition and Modularity Plan

1. **Phase 1: Implement DB-Backed Streaming**
   - Implement ContentProcessorService that wraps existing podcast processing (TranscriptProcessor, SummaryGeneratorService, etc.).
   - On job processing, summary chunks are appended to the DB immediately, and the UI receives incremental updates via Supabase realtime subscriptions.

2. **Phase 2: Adding Direct Streaming (SSE)**
   - Abstract the summary delivery mechanism by defining a StreamDeliveryService interface.
   - Implement an SSE-based service that pushes summary chunks directly to the client.
   - Allow toggling or hybrid mode to compare performance and UX.

## Environment and Configuration

- **API Service Environment Variables:**
  SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY, REDIS_URL, YOUTUBE_API_KEY, SPOTIFY_ACCESS_TOKEN

- **Worker Service Environment Variables:**
  SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY, REDIS_URL, YOUTUBE_OAUTH_CLIENT_ID, YOUTUBE_OAUTH_CLIENT_SECRET, YOUTUBE_OAUTH_REFRESH_TOKEN, ANTHROPIC_API_KEY

- Redis connection is configured via Railway environment variables (REDIS_HOST, REDIS_PORT, REDIS_PASSWORD, etc.).

## Summary

The new design aims to provide near real-time summary streaming via a modular approach. The initial implementation uses DB-backed streaming to deliver incremental updates to the UI, significantly reducing the perceived latency from the previous 10–30 seconds down to a few hundred milliseconds per chunk. Down the line, the delivery mechanism can be swapped for direct SSE-based streaming to push updates immediately over a persistent connection.

## Status Flow
IN_QUEUE -> FETCHING_TRANSCRIPT -> GENERATING_SUMMARY -> COMPLETED
(Any state can transition to FAILED on error)

## Implementation Details

1. Platform Clients
Both API and Worker services use instance-based clients:

YouTubeApiClient:
- Constructor takes apiKey and optional oauth2Client
- Handles video info retrieval and transcript fetching

SpotifyApiClient:
- Constructor takes accessToken
- Handles episode metadata retrieval

2. Real-time Updates
Frontend subscribes to Supabase real-time updates on the summaries table
Updates UI based on summary.status and content changes

3. Error Handling
- API errors return appropriate HTTP status codes
- Worker errors update summary status to FAILED with error details
- All errors are logged and monitored

## Configuration Required

API Service Environment Variables:
SUPABASE_URL=
SUPABASE_SERVICE_ROLE_KEY=
REDIS_URL=
YOUTUBE_API_KEY=
SPOTIFY_ACCESS_TOKEN=

Worker Service Environment Variables:
SUPABASE_URL=
SUPABASE_SERVICE_ROLE_KEY=
REDIS_URL=
YOUTUBE_OAUTH_CLIENT_ID=
YOUTUBE_OAUTH_CLIENT_SECRET=
YOUTUBE_OAUTH_REFRESH_TOKEN=
ANTHROPIC_API_KEY=

## Common Failure Scenarios

1. Invalid/private YouTube URL
   - Handled by: API validation and worker verification
   - Result: FAILED status with specific error message

2. No matching YouTube video for Spotify episode
   - Handled by: Worker matching process
   - Result: FAILED status with "No matching video found" message

3. No available transcript
   - Handled by: Worker's transcript fetching fallback system
   - Result: FAILED status with "No transcript available" message

4. Rate limiting from external services
   - Handled by: Retry mechanisms with exponential backoff
   - Result: Temporary delays or FAILED status if retries exhausted

5. Network timeouts
   - Handled by: Retry mechanisms
   - Result: Temporary delays or FAILED status if retries exhausted

## API Endpoints
For detailed implementation of these endpoints, see docs/routes-and-services.md

1. Podcast Submission
   POST /api/podcasts
   - Accepts: { url: string, type: 'youtube' | 'spotify' }
   - Returns: { podcast: PodcastRecord, summary: SummaryRecord }
   - Purpose: Initial submission and job creation
   - Auth: Required

2. Summary Status
   GET /api/summaries/:id
   - Returns: SummaryRecord with current status and content
   - Purpose: Direct fetch of summary data
   - Note: Most clients use Supabase subscriptions instead
   - Auth: Required

3. Summary Stream
   GET /api/summaries/:id/stream
   - Returns: Server-sent events of summary generation
   - Purpose: Legacy endpoint for non-Supabase streaming
   - Note: Prefer Supabase real-time subscriptions
   - Auth: Required

Note: While we maintain these REST endpoints, our primary real-time updates 
flow through Supabase subscriptions. The frontend typically only uses 
POST /api/podcasts for submission, then relies on Supabase for all 
subsequent updates. 